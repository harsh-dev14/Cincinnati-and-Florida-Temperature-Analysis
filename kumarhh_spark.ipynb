{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03444f68-6fcc-4794-96b1-b65233c5a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb2a7169-5b5a-46bc-936f-97668a83ca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ./weather_data/2015_72429793812.csv\n",
      "Downloaded: ./weather_data/2015_99495199999.csv\n",
      "Downloaded: ./weather_data/2016_72429793812.csv\n",
      "Downloaded: ./weather_data/2017_72429793812.csv\n",
      "Downloaded: ./weather_data/2017_99495199999.csv\n",
      "Downloaded: ./weather_data/2018_72429793812.csv\n",
      "Downloaded: ./weather_data/2018_99495199999.csv\n",
      "Downloaded: ./weather_data/2019_72429793812.csv\n",
      "Downloaded: ./weather_data/2019_99495199999.csv\n",
      "Downloaded: ./weather_data/2020_72429793812.csv\n",
      "Downloaded: ./weather_data/2020_99495199999.csv\n",
      "Downloaded: ./weather_data/2021_72429793812.csv\n",
      "Downloaded: ./weather_data/2021_99495199999.csv\n",
      "Downloaded: ./weather_data/2022_72429793812.csv\n",
      "Downloaded: ./weather_data/2022_99495199999.csv\n",
      "Downloaded: ./weather_data/2023_72429793812.csv\n",
      "Downloaded: ./weather_data/2023_99495199999.csv\n",
      "Downloaded: ./weather_data/2024_72429793812.csv\n",
      "Downloaded: ./weather_data/2024_99495199999.csv\n",
      "Cincinnati --> Year: 2015, Station: 72429793812, Count: 365\n",
      "Florida --> Year: 2015, Station: 99495199999, Count: 355\n",
      "Cincinnati --> Year: 2016, Station: 72429793812, Count: 366\n",
      "Cincinnati --> Year: 2017, Station: 72429793812, Count: 365\n",
      "Florida --> Year: 2017, Station: 99495199999, Count: 283\n",
      "Cincinnati --> Year: 2018, Station: 72429793812, Count: 365\n",
      "Florida --> Year: 2018, Station: 99495199999, Count: 363\n",
      "Cincinnati --> Year: 2019, Station: 72429793812, Count: 365\n",
      "Florida --> Year: 2019, Station: 99495199999, Count: 345\n",
      "Cincinnati --> Year: 2020, Station: 72429793812, Count: 366\n",
      "Florida --> Year: 2020, Station: 99495199999, Count: 365\n",
      "Cincinnati --> Year: 2021, Station: 72429793812, Count: 365\n",
      "Florida --> Year: 2021, Station: 99495199999, Count: 104\n",
      "Cincinnati --> Year: 2022, Station: 72429793812, Count: 365\n",
      "Florida --> Year: 2022, Station: 99495199999, Count: 259\n",
      "Cincinnati --> Year: 2023, Station: 72429793812, Count: 365\n",
      "Florida --> Year: 2023, Station: 99495199999, Count: 276\n",
      "Cincinnati --> Year: 2024, Station: 72429793812, Count: 305\n",
      "Florida --> Year: 2024, Station: 99495199999, Count: 133\n",
      "\n",
      "Total Results: 19 (as expected)\n"
     ]
    }
   ],
   "source": [
    "# Base URL for NCEI Bulk Data Download\n",
    "base_url = \"https://www.ncei.noaa.gov/data/global-summary-of-the-day/access\"\n",
    "data_directory = \"./weather_data\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "# Download weather data for Cincinnati and Florida for years 2015 to 2024\n",
    "years = range(2015, 2025)\n",
    "stations = [\"72429793812\", \"99495199999\"]\n",
    "\n",
    "def download_file(url, local_filename):\n",
    "    \"\"\"Download file from a URL and save it locally.\"\"\"\n",
    "    try:\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()  # Raise an error for bad responses\n",
    "            with open(local_filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"Downloaded: {local_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}. Error: {e}\")\n",
    "\n",
    "def download_data_for_year(year):\n",
    "    \"\"\"Download data for all stations for a specific year.\"\"\"\n",
    "    year_url = f\"{base_url}/{year}/\"\n",
    "    response = requests.get(year_url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error accessing: {year_url}\")\n",
    "        return\n",
    "\n",
    "    # Parse HTML to find all file links\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "\n",
    "    # Download data for each station\n",
    "    for station in stations:\n",
    "        filename = f\"{station}.csv\"\n",
    "        for link in links:\n",
    "            if link.get('href') == filename:\n",
    "                file_url = f\"{year_url}{filename}\"\n",
    "                local_path = os.path.join(data_directory, f\"{year}_{filename}\")\n",
    "                download_file(file_url, local_path)\n",
    "                break\n",
    "\n",
    "# Download data for each year\n",
    "for year in years:\n",
    "    download_data_for_year(year)\n",
    "\n",
    "# List to store the counts of the datasets\n",
    "dataset_counts = []\n",
    "\n",
    "for year in years:\n",
    "    for station in stations:\n",
    "        # Skip 2016 for Florida as data is not available\n",
    "        if year == 2016 and station == \"99495199999\":\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(data_directory, f\"{year}_{station}.csv\")\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Read the CSV file using Pandas\n",
    "                df = pd.read_csv(file_path)\n",
    "                row_count = len(df)\n",
    "                dataset_counts.append((year, station, row_count))\n",
    "                location = \"Cincinnati\" if station == \"72429793812\" else \"Florida\"\n",
    "                print(f\"{location} --> Year: {year}, Station: {station}, Count: {row_count}\")\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"File is empty: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}. Error: {e}\")\n",
    "        else:\n",
    "            print(f\"File not found for Year: {year}, Station: {station}\")\n",
    "\n",
    "# Display total results\n",
    "if len(dataset_counts) == 19:\n",
    "    print(\"\\nTotal Results: 19 (as expected)\")\n",
    "else:\n",
    "    print(f\"\\nTotal Results: {len(dataset_counts)} (unexpected)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa097c4f-a6c5-475c-8b9f-a57f93bfab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/03 20:46:23 WARN Utils: Your hostname, Harshs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.4.58 instead (on interface en0)\n",
      "24/11/03 20:46:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/03 20:46:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/03 20:46:26 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hottest Days by Year (Cincinnati):\n",
      "+----------+-----+------------------------------------------------+-----------+----+\n",
      "|DATE      |MAX  |NAME                                            |STATION    |YEAR|\n",
      "+----------+-----+------------------------------------------------+-----------+----+\n",
      "|2015-06-12|91.9 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2015|\n",
      "|2016-07-24|93.9 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2016|\n",
      "|2017-07-22|91.9 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2017|\n",
      "|2018-07-04|96.1 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2018|\n",
      "|2019-09-30|95.0 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2019|\n",
      "|2020-07-05|93.9 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2020|\n",
      "|2021-08-12|95.0 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2021|\n",
      "|2022-06-14|96.1 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2022|\n",
      "|2023-08-23|96.1 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2023|\n",
      "|2024-08-30|100.9|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2024|\n",
      "+----------+-----+------------------------------------------------+-----------+----+\n",
      "\n",
      "\n",
      "Hottest Days by Year (Florida):\n",
      "+----------+----+---------------------------------+-----------+----+\n",
      "|DATE      |MAX |NAME                             |STATION    |YEAR|\n",
      "+----------+----+---------------------------------+-----------+----+\n",
      "|2015-07-28|90.0|SEBASTIAN INLET STATE PARK, FL US|99495199999|2015|\n",
      "|2017-05-13|88.3|SEBASTIAN INLET STATE PARK, FL US|99495199999|2017|\n",
      "|2018-09-15|90.1|SEBASTIAN INLET STATE PARK, FL US|99495199999|2018|\n",
      "|2019-09-06|91.6|SEBASTIAN INLET STATE PARK, FL US|99495199999|2019|\n",
      "|2020-04-13|91.8|SEBASTIAN INLET STATE PARK, FL US|99495199999|2020|\n",
      "|2021-04-18|86.2|SEBASTIAN INLET STATE PARK, FL US|99495199999|2021|\n",
      "|2022-05-06|89.6|SEBASTIAN INLET STATE PARK, FL US|99495199999|2022|\n",
      "|2023-07-09|90.9|SEBASTIAN INLET STATE PARK, FL US|99495199999|2023|\n",
      "|2024-05-14|86.7|SEBASTIAN INLET STATE PARK, FL US|99495199999|2024|\n",
      "+----------+----+---------------------------------+-----------+----+\n",
      "\n",
      "\n",
      "Overall Hottest Day by Year (Cincinnati and Florida):\n",
      "+----------+-----+------------------------------------------------+-----------+----+\n",
      "|DATE      |MAX  |NAME                                            |STATION    |YEAR|\n",
      "+----------+-----+------------------------------------------------+-----------+----+\n",
      "|2015-06-12|91.9 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2015|\n",
      "|2016-07-24|93.9 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2016|\n",
      "|2017-07-22|91.9 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2017|\n",
      "|2018-07-04|96.1 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2018|\n",
      "|2019-09-30|95.0 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2019|\n",
      "|2020-07-05|93.9 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2020|\n",
      "|2021-08-12|95.0 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2021|\n",
      "|2022-06-14|96.1 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2022|\n",
      "|2023-08-23|96.1 |CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2023|\n",
      "|2024-08-30|100.9|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|72429793812|2024|\n",
      "+----------+-----+------------------------------------------------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Weather Data Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data_directory = \"./weather_data\"\n",
    "\n",
    "# Years for which data is available\n",
    "years = range(2015, 2025)\n",
    "stations = [\"72429793812\", \"99495199999\"]\n",
    "\n",
    "# Lists to store hottest day data\n",
    "hottest_days_cincinnati = []\n",
    "hottest_days_florida = []\n",
    "hottest_days_overall = []\n",
    "\n",
    "for year in years:\n",
    "    year_data = []\n",
    "    for station in stations:\n",
    "        # Skip 2016 for Florida as data may not be available\n",
    "        if year == 2016 and station == \"99495199999\":\n",
    "            continue\n",
    "\n",
    "        file_path = f\"{data_directory}/{year}_{station}.csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            # Load data and filter out invalid temperature values\n",
    "            df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "            df = df.filter(df[\"MAX\"] != 9999.9)\n",
    "\n",
    "            # Find the hottest day for this station if data is available\n",
    "            if df.count() > 0:\n",
    "                hottest_day = df.orderBy(df[\"MAX\"].desc()).first()\n",
    "                hottest_day_data = {\n",
    "                    \"YEAR\": year,\n",
    "                    \"STATION\": hottest_day[\"STATION\"],\n",
    "                    \"NAME\": hottest_day[\"NAME\"],\n",
    "                    \"DATE\": hottest_day[\"DATE\"],\n",
    "                    \"MAX\": hottest_day[\"MAX\"]\n",
    "                }\n",
    "                year_data.append(hottest_day_data)\n",
    "\n",
    "                # Separate lists for Cincinnati and Florida\n",
    "                if station == \"72429793812\":\n",
    "                    hottest_days_cincinnati.append(hottest_day_data)\n",
    "                elif station == \"99495199999\":\n",
    "                    hottest_days_florida.append(hottest_day_data)\n",
    "\n",
    "    # Determine the hottest day overall for the year by comparing both stations\n",
    "    if year_data:\n",
    "        hottest_day_year = max(year_data, key=lambda x: x[\"MAX\"])\n",
    "        hottest_days_overall.append(hottest_day_year)\n",
    "\n",
    "# Convert the results into Spark DataFrames\n",
    "hottest_days_cincinnati_df = spark.createDataFrame(hottest_days_cincinnati)\n",
    "hottest_days_florida_df = spark.createDataFrame(hottest_days_florida)\n",
    "hottest_days_overall_df = spark.createDataFrame(hottest_days_overall)\n",
    "\n",
    "# Display results using show() for Spark DataFrames\n",
    "print(\"\\nHottest Days by Year (Cincinnati):\")\n",
    "hottest_days_cincinnati_df.sort(\"YEAR\").show(truncate=False)\n",
    "\n",
    "print(\"\\nHottest Days by Year (Florida):\")\n",
    "hottest_days_florida_df.sort(\"YEAR\").show(truncate=False)\n",
    "\n",
    "print(\"\\nOverall Hottest Day by Year (Cincinnati and Florida):\")\n",
    "hottest_days_overall_df.sort(\"YEAR\").show(truncate=False)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dde1ed3b-2859-4461-9111-06f53373b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coldest Day Overall in March (2015-2024) across Cincinnati and Florida:\n",
      "\n",
      "+-------------------------------------------------+\n",
      "| Year  | Station ID      | Station Name              | Date       | Min Temp (°F)   |\n",
      "+-------------------------------------------------+\n",
      "| 2015  | 72429793812     | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US | <10 | 3.2             |\n",
      "+-------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Weather Data Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Directory and years range\n",
    "data_directory = \"./weather_data\"\n",
    "years = range(2015, 2025)\n",
    "stations = [\"72429793812\", \"99495199999\"]\n",
    "\n",
    "# List to store coldest day data for each station across all years\n",
    "march_min_temps = []\n",
    "\n",
    "# Find the coldest day in March across all years for each station\n",
    "for year in years:\n",
    "    for station in stations:\n",
    "        file_path = f\"{data_directory}/{year}_{station}.csv\"\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Load data into a Spark DataFrame\n",
    "            df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "            df = df.withColumn(\"DATE\", F.to_date(df[\"DATE\"]))\n",
    "\n",
    "            # Filter for March and valid temperature values\n",
    "            march_df = df.filter((F.month(df[\"DATE\"]) == 3) & (df[\"MIN\"] != 9999.9))\n",
    "            \n",
    "            # Find the coldest day in March for this DataFrame, if available\n",
    "            if march_df.count() > 0:\n",
    "                coldest_day = march_df.orderBy(\"MIN\").first()\n",
    "                march_min_temps.append({\n",
    "                    \"YEAR\": year,\n",
    "                    \"STATION\": str(coldest_day[\"STATION\"]),  # Ensure Station ID is stored as a string\n",
    "                    \"NAME\": coldest_day[\"NAME\"],\n",
    "                    \"DATE\": coldest_day[\"DATE\"],\n",
    "                    \"MIN\": coldest_day[\"MIN\"]\n",
    "                })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "all_march_min_df = spark.createDataFrame(march_min_temps)\n",
    "\n",
    "# Find the overall coldest day in March across all years\n",
    "if all_march_min_df.count() > 0:\n",
    "    coldest_overall_day = all_march_min_df.orderBy(\"MIN\").first()\n",
    "\n",
    "    # Prepare data for display\n",
    "    results = [\n",
    "        {\n",
    "            \"Year\": int(coldest_overall_day[\"YEAR\"]),\n",
    "            \"Station ID\": coldest_overall_day[\"STATION\"],\n",
    "            \"Station Name\": coldest_overall_day[\"NAME\"],\n",
    "            \"Date\": coldest_overall_day[\"DATE\"],\n",
    "            \"Min Temp (°F)\": round(coldest_overall_day[\"MIN\"], 1)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Display the result in a well-formatted table\n",
    "    print(\"\\nColdest Day Overall in March (2015-2024) across Cincinnati and Florida:\\n\")\n",
    "    print(\"+\" + \"-\" * 49 + \"+\")\n",
    "    print(\"| {:<5} | {:<15} | {:<25} | {:<10} | {:<15} |\".format(\"Year\", \"Station ID\", \"Station Name\", \"Date\", \"Min Temp (°F)\"))\n",
    "    print(\"+\" + \"-\" * 49 + \"+\")\n",
    "    for result in results:\n",
    "        print(\"| {:<5} | {:<15} | {:<25} | {:<10} | {:<15} |\".format(result[\"Year\"], result[\"Station ID\"], result[\"Station Name\"], result[\"Date\"], result[\"Min Temp (°F)\"]))\n",
    "    print(\"+\" + \"-\" * 49 + \"+\")\n",
    "else:\n",
    "    print(\"No data available for the specified range.\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b75368d-e17a-4aac-b3a5-6370442940d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year with Most Precipitation for Cincinnati and Florida:\n",
      "\n",
      "+----------------------------------------------------------+\n",
      "| Year  | Station         | Station Name              | Mean PRCP       |\n",
      "+----------------------------------------------------------+\n",
      "| 2024  | 72429793812     | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US | 5.36            |\n",
      "| 2021  | 99495199999     | SEBASTIAN INLET STATE PARK, FL US | 0.0             |\n",
      "+----------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Weather Data Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Directory and years range\n",
    "data_directory = \"./weather_data\"\n",
    "years = range(2015, 2025)\n",
    "\n",
    "# Calculate mean precipitation by year for Cincinnati\n",
    "cincinnati_precip_data = []\n",
    "\n",
    "for year in years:\n",
    "    file_path = f\"{data_directory}/{year}_72429793812.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        # Load data into a Spark DataFrame\n",
    "        df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "        # Filter out invalid precipitation values\n",
    "        df = df.filter(df[\"PRCP\"] != 9999.9)\n",
    "\n",
    "        # Calculate mean precipitation if data is available\n",
    "        if df.count() > 0:\n",
    "            mean_prcp = df.agg(F.mean(\"PRCP\")).first()[0]\n",
    "            cincinnati_precip_data.append({\n",
    "                \"YEAR\": year,\n",
    "                \"STATION\": str(df.select(\"STATION\").first()[0]),  # Convert to string\n",
    "                \"NAME\": df.select(\"NAME\").first()[0],\n",
    "                \"Mean_PRCP\": mean_prcp\n",
    "            })\n",
    "\n",
    "cincinnati_precip_df = spark.createDataFrame(cincinnati_precip_data)\n",
    "cincinnati_result = cincinnati_precip_df.orderBy(F.desc(\"Mean_PRCP\")).first() if cincinnati_precip_df.count() > 0 else None\n",
    "\n",
    "# Calculate mean precipitation by year for Florida (excluding 2016 as data is unavailable)\n",
    "florida_precip_data = []\n",
    "\n",
    "for year in years:\n",
    "    if year == 2016:\n",
    "        continue\n",
    "    file_path = f\"{data_directory}/{year}_99495199999.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "        df = df.filter(df[\"PRCP\"] != 9999.9)\n",
    "\n",
    "        if df.count() > 0:\n",
    "            mean_prcp = df.agg(F.mean(\"PRCP\")).first()[0]\n",
    "            florida_precip_data.append({\n",
    "                \"YEAR\": year,\n",
    "                \"STATION\": str(df.select(\"STATION\").first()[0]),  # Convert to string\n",
    "                \"NAME\": df.select(\"NAME\").first()[0],\n",
    "                \"Mean_PRCP\": mean_prcp\n",
    "            })\n",
    "\n",
    "florida_precip_df = spark.createDataFrame(florida_precip_data)\n",
    "florida_result = florida_precip_df.orderBy(F.desc(\"Mean_PRCP\")).first() if florida_precip_df.count() > 0 else None\n",
    "\n",
    "# Prepare data for display\n",
    "results = []\n",
    "\n",
    "if cincinnati_result:\n",
    "    results.append({\n",
    "        \"Year\": int(cincinnati_result[\"YEAR\"]),\n",
    "        \"Station\": cincinnati_result[\"STATION\"],\n",
    "        \"Station Name\": cincinnati_result[\"NAME\"],\n",
    "        \"Mean PRCP\": round(cincinnati_result[\"Mean_PRCP\"], 2)\n",
    "    })\n",
    "\n",
    "if florida_result:\n",
    "    results.append({\n",
    "        \"Year\": int(florida_result[\"YEAR\"]),\n",
    "        \"Station\": florida_result[\"STATION\"],\n",
    "        \"Station Name\": florida_result[\"NAME\"],\n",
    "        \"Mean PRCP\": round(florida_result[\"Mean_PRCP\"], 2)\n",
    "    })\n",
    "\n",
    "# Display the results in a well-formatted table\n",
    "if results:\n",
    "    print(\"\\nYear with Most Precipitation for Cincinnati and Florida:\\n\")\n",
    "    print(\"+\" + \"-\" * 58 + \"+\")\n",
    "    print(\"| {:<5} | {:<15} | {:<25} | {:<15} |\".format(\"Year\", \"Station\", \"Station Name\", \"Mean PRCP\"))\n",
    "    print(\"+\" + \"-\" * 58 + \"+\")\n",
    "    for result in results:\n",
    "        print(\"| {:<5} | {:<15} | {:<25} | {:<15} |\".format(result[\"Year\"], result[\"Station\"], result[\"Station Name\"], result[\"Mean PRCP\"]))\n",
    "    print(\"+\" + \"-\" * 58 + \"+\")\n",
    "else:\n",
    "    print(\"No precipitation data available for the specified range.\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7df4012-4ef7-4ceb-bd97-27ecc727483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of Missing Values for Wind Gust (column GUST) for Cincinnati and Florida in 2024:\n",
      "\n",
      "Cincinnati: 39.67%\n",
      "Florida: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Weather Data Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define file paths for 2024 data\n",
    "cincinnati_2024_file = \"./weather_data/2024_72429793812.csv\"\n",
    "florida_2024_file = \"./weather_data/2024_99495199999.csv\"\n",
    "\n",
    "# Initialize missing percentage variables\n",
    "cincinnati_missing_percentage = None\n",
    "florida_missing_percentage = None\n",
    "\n",
    "# Load 2024 data for Cincinnati if the file exists\n",
    "if os.path.exists(cincinnati_2024_file):\n",
    "    cincinnati_df = spark.read.csv(cincinnati_2024_file, header=True, inferSchema=True)\n",
    "    # Count missing GUST values (marked as 999.9)\n",
    "    cincinnati_missing_count = cincinnati_df.filter(cincinnati_df[\"GUST\"] == 999.9).count()\n",
    "    cincinnati_total_count = cincinnati_df.count()\n",
    "    if cincinnati_total_count > 0:\n",
    "        cincinnati_missing_percentage = (cincinnati_missing_count / cincinnati_total_count) * 100\n",
    "\n",
    "# Load 2024 data for Florida if the file exists\n",
    "if os.path.exists(florida_2024_file):\n",
    "    florida_df = spark.read.csv(florida_2024_file, header=True, inferSchema=True)\n",
    "    florida_missing_count = florida_df.filter(florida_df[\"GUST\"] == 999.9).count()\n",
    "    florida_total_count = florida_df.count()\n",
    "    if florida_total_count > 0:\n",
    "        florida_missing_percentage = (florida_missing_count / florida_total_count) * 100\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nPercentage of Missing Values for Wind Gust (column GUST) for Cincinnati and Florida in 2024:\\n\")\n",
    "if cincinnati_missing_percentage is not None:\n",
    "    print(f\"Cincinnati: {cincinnati_missing_percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"Cincinnati data file for 2024 not found.\")\n",
    "\n",
    "if florida_missing_percentage is not None:\n",
    "    print(f\"Florida: {florida_missing_percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"Florida data file for 2024 not found.\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf6e5f1b-4ade-4694-89bd-dea888e22ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature Statistics for Cincinnati for Each Month in 2020:\n",
      "\n",
      "╒═══════════╤═════════════╤══════════════════════════╤═══════════════╤═════════════╕\n",
      "│ MONTH     │   Mean_TEMP │   StandardDeviation_TEMP │   Median_TEMP │   Mode_TEMP │\n",
      "╞═══════════╪═════════════╪══════════════════════════╪═══════════════╪═════════════╡\n",
      "│ January   │       37.95 │                     8.35 │         37.70 │       24.70 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ February  │       36.59 │                     7.90 │         36.00 │       25.90 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ March     │       49.07 │                     8.78 │         47.80 │       39.60 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ April     │       51.78 │                     7.31 │         51.10 │       39.20 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ May       │       60.89 │                     9.31 │         63.70 │       73.90 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ June      │       72.55 │                     4.90 │         73.95 │       70.70 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ July      │       77.60 │                     2.34 │         77.90 │       72.50 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ August    │       73.35 │                     3.49 │         73.70 │       67.40 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ September │       66.10 │                     7.12 │         66.15 │       54.70 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ October   │       55.19 │                     6.73 │         54.00 │       41.40 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ November  │       48.00 │                     6.83 │         47.70 │       47.70 │\n",
      "├───────────┼─────────────┼──────────────────────────┼───────────────┼─────────────┤\n",
      "│ December  │       35.99 │                     6.64 │         35.20 │       32.10 │\n",
      "╘═══════════╧═════════════╧══════════════════════════╧═══════════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# File path for Cincinnati 2020 data\n",
    "cincinnati_2020_file = \"./weather_data/2020_72429793812.csv\"\n",
    "\n",
    "# Load 2020 data for Cincinnati if the file exists\n",
    "if os.path.exists(cincinnati_2020_file):\n",
    "    df = pd.read_csv(cincinnati_2020_file)\n",
    "    \n",
    "    # Filter out invalid temperature values and rows with missing TEMP values\n",
    "    df = df[df[\"TEMP\"] != 9999.9].dropna(subset=[\"TEMP\"])\n",
    "    df[\"TEMP\"] = df[\"TEMP\"].astype(float)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    df[\"MONTH\"] = df[\"DATE\"].dt.month_name()  # Get month name directly\n",
    "\n",
    "    # Define the month order\n",
    "    month_order = {\n",
    "        \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \"May\": 5, \"June\": 6,\n",
    "        \"July\": 7, \"August\": 8, \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n",
    "    }\n",
    "\n",
    "    # Calculate statistics for each month\n",
    "    stats_results = []\n",
    "    for month in df[\"MONTH\"].unique():\n",
    "        month_df = df[df[\"MONTH\"] == month]\n",
    "        if not month_df.empty:\n",
    "            mean_temp = month_df[\"TEMP\"].mean()\n",
    "            std_dev_temp = month_df[\"TEMP\"].std()\n",
    "            median_temp = month_df[\"TEMP\"].median()\n",
    "            \n",
    "            # Calculate mode, handling cases where mode might be a scalar\n",
    "            mode_result = stats.mode(month_df[\"TEMP\"], nan_policy='omit')\n",
    "            mode_temp = mode_result.mode[0] if hasattr(mode_result.mode, \"_len_\") else mode_result.mode\n",
    "            \n",
    "            stats_results.append({\n",
    "                \"MONTH\": month,\n",
    "                \"Mean_TEMP\": mean_temp,\n",
    "                \"StandardDeviation_TEMP\": std_dev_temp,\n",
    "                \"Median_TEMP\": median_temp,\n",
    "                \"Mode_TEMP\": mode_temp\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame and sort by month order\n",
    "    final_stats_df = pd.DataFrame(stats_results)\n",
    "    final_stats_df[\"MONTH_ORDER\"] = final_stats_df[\"MONTH\"].map(month_order)\n",
    "    final_stats_df = final_stats_df.sort_values(by=\"MONTH_ORDER\").drop(columns=\"MONTH_ORDER\")\n",
    "\n",
    "    # Display results in a well-formatted table\n",
    "    print(\"\\nTemperature Statistics for Cincinnati for Each Month in 2020:\\n\")\n",
    "    print(tabulate(final_stats_df, headers=\"keys\", tablefmt=\"fancy_grid\", floatfmt=\".2f\", showindex=False))\n",
    "else:\n",
    "    print(\"Cincinnati 2020 data file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "700366a9-d6e7-4958-93fb-eb034e4f18eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/03 20:53:57 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Days with the Lowest Wind Chill for Cincinnati in 2017:\n",
      "\n",
      "╒══════════════════════════════════════════════════╤════════════╤════════╤════════╤══════════════╕\n",
      "│ NAME                                             │ DATE       │   TEMP │   WDSP │   Wind_Chill │\n",
      "╞══════════════════════════════════════════════════╪════════════╪════════╪════════╪══════════════╡\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-01-07 │  10.50 │   7.00 │        -0.41 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-31 │  11.00 │   5.30 │         2.03 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-27 │  13.00 │   5.80 │         3.82 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-28 │  13.60 │   5.80 │         4.53 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-01-06 │  13.60 │   5.50 │         4.87 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-01-08 │  15.90 │   5.20 │         7.93 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-25 │  25.80 │  13.50 │        14.29 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-30 │  21.60 │   5.30 │        14.54 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-01-05 │  22.20 │   5.80 │        14.75 │\n",
      "├──────────────────────────────────────────────────┼────────────┼────────┼────────┼──────────────┤\n",
      "│ CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US │ 2017-12-26 │  23.30 │   6.20 │        15.69 │\n",
      "╘══════════════════════════════════════════════════╧════════════╧════════╧════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Lowest Wind Chill for Cincinnati 2017\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# File path for Cincinnati 2017 data\n",
    "cincinnati_2017_file = \"./weather_data/2017_72429793812.csv\"\n",
    "\n",
    "# Load the 2017 data for Cincinnati if the file exists\n",
    "if os.path.exists(cincinnati_2017_file):\n",
    "    # Load data into a Spark DataFrame\n",
    "    df = spark.read.csv(cincinnati_2017_file, header=True, inferSchema=True)\n",
    "\n",
    "    # Convert TEMP and WDSP to float and filter for relevant conditions\n",
    "    df_filtered = df.withColumn(\"TEMP\", F.col(\"TEMP\").cast(\"float\")) \\\n",
    "                    .withColumn(\"WDSP\", F.col(\"WDSP\").cast(\"float\")) \\\n",
    "                    .filter((F.col(\"TEMP\") < 50) & (F.col(\"WDSP\") > 3)) \\\n",
    "                    .dropna(subset=[\"TEMP\", \"WDSP\"])\n",
    "\n",
    "    # Calculate Wind Chill using the formula\n",
    "    wind_chill_formula = (\n",
    "        35.74 + (0.6215 * F.col(\"TEMP\")) - (35.75 * (F.col(\"WDSP\") ** 0.16)) +\n",
    "        (0.4275 * F.col(\"TEMP\") * (F.col(\"WDSP\") ** 0.16))\n",
    "    )\n",
    "    \n",
    "    df_filtered = df_filtered.withColumn(\"Wind_Chill\", wind_chill_formula)\n",
    "\n",
    "    # Get the top 10 days with the lowest Wind Chill\n",
    "    top_10_lowest_wc = df_filtered.select(\"NAME\", \"DATE\", \"TEMP\", \"WDSP\", \"Wind_Chill\") \\\n",
    "                                   .orderBy(\"Wind_Chill\") \\\n",
    "                                   .limit(10)\n",
    "\n",
    "    # Collect results to display\n",
    "    top_10_results = top_10_lowest_wc.toPandas()\n",
    "\n",
    "    # Display results in a well-formatted table\n",
    "    print(\"\\nTop 10 Days with the Lowest Wind Chill for Cincinnati in 2017:\\n\")\n",
    "    print(tabulate(top_10_results, headers=\"keys\", tablefmt=\"fancy_grid\", floatfmt=\".2f\", showindex=False))\n",
    "\n",
    "else:\n",
    "    print(\"Cincinnati 2017 data file not found.\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72b09fdc-5cf4-4a77-b50e-a5525fe2754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Days with Extreme Weather Conditions in Florida from 2015 to 2024: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Extreme Weather Days Count for Florida\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Directory and years for Florida files\n",
    "data_directory = \"./weather_data\"\n",
    "years = [y for y in range(2015, 2025) if y != 2016]  # Exclude 2016 if data is unavailable\n",
    "\n",
    "# Initialize a counter for extreme weather days\n",
    "extreme_weather_days_count = 0\n",
    "\n",
    "# Load and process data for each year in the specified range\n",
    "for year in years:\n",
    "    florida_file = f\"{data_directory}/{year}_99495199999.csv\"\n",
    "    \n",
    "    if os.path.exists(florida_file):\n",
    "        # Load data into a Spark DataFrame\n",
    "        df = spark.read.csv(florida_file, header=True, inferSchema=True)\n",
    "\n",
    "        # Ensure each FRSHTT value is a six-character string\n",
    "        df = df.withColumn('FRSHTT', F.lpad(F.col('FRSHTT').cast('string'), 6, '0'))\n",
    "\n",
    "        # Count days with any extreme weather indicator\n",
    "        extreme_weather_days = df.filter(\n",
    "            F.expr(\"array_contains(split(FRSHTT, ''), '1')\")\n",
    "        )\n",
    "\n",
    "        # Update the total count of extreme weather days\n",
    "        extreme_weather_days_count += extreme_weather_days.count()\n",
    "\n",
    "# Display the result\n",
    "print(f\"\\nNumber of Days with Extreme Weather Conditions in Florida from 2015 to 2024: {extreme_weather_days_count}\\n\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "970cd728-fa67-4b86-8467-a7fe2299a508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/03 21:18:36 WARN Instrumentation: [d88dcc24] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/11/03 21:18:36 WARN Instrumentation: [e7a15bac] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/11/03 21:18:37 WARN DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 2 (= number of training instances)\n",
      "24/11/03 21:18:37 WARN DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 2 (= number of training instances)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression November Metrics: RMSE = 0.00, MAE = 0.00, R2 = 1.00\n",
      "Linear Regression December Metrics: RMSE = 0.00, MAE = 0.00, R2 = 1.00\n",
      "Random Forest November Metrics: RMSE = 8.29, MAE = 8.22, R2 = -14.57\n",
      "Random Forest December Metrics: RMSE = 6.32, MAE = 6.30, R2 = -38.94\n",
      "\n",
      "Best model is November (Linear Regression) with R2 = 1.00\n",
      "Predicted Maximum Temperature for Cincinnati in November 2024: 84.30°F\n",
      "Predicted Maximum Temperature for Cincinnati in December 2024: 62.00°F\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, data):\n",
    "    predictions = model.transform(data)\n",
    "    evaluator = RegressionEvaluator(labelCol=\"MAX_TEMP\", predictionCol=\"prediction\")\n",
    "    \n",
    "    rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
    "    mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
    "    r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Cincinnati Temperature Prediction\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load 2022 and 2023 data for Cincinnati\n",
    "data_directory = \"./weather_data\"\n",
    "cincinnati_files = [f\"{data_directory}/{year}_72429793812.csv\" for year in [2022, 2023]]\n",
    "\n",
    "# Load and concatenate data\n",
    "cincinnati_data = spark.read.csv(cincinnati_files[0], header=True, inferSchema=True)\n",
    "for file in cincinnati_files[1:]:\n",
    "    if os.path.exists(file):\n",
    "        temp_df = spark.read.csv(file, header=True, inferSchema=True)\n",
    "        cincinnati_data = cincinnati_data.union(temp_df)\n",
    "\n",
    "# Filter data for valid MAX temperatures and convert DATE\n",
    "cincinnati_data = cincinnati_data.filter(cincinnati_data[\"MAX\"] != 9999.9)\n",
    "cincinnati_data = cincinnati_data.withColumn(\"DATE\", F.to_date(\"DATE\")) \\\n",
    "                                   .withColumn(\"YEAR\", F.year(\"DATE\")) \\\n",
    "                                   .withColumn(\"MONTH\", F.month(\"DATE\"))\n",
    "\n",
    "# Extract max temperatures for November and December for each year\n",
    "november_data = cincinnati_data.filter(cincinnati_data[\"MONTH\"] == 11) \\\n",
    "                               .groupBy(\"YEAR\") \\\n",
    "                               .agg(F.max(\"MAX\").alias(\"MAX_TEMP\"))\n",
    "\n",
    "december_data = cincinnati_data.filter(cincinnati_data[\"MONTH\"] == 12) \\\n",
    "                               .groupBy(\"YEAR\") \\\n",
    "                               .agg(F.max(\"MAX\").alias(\"MAX_TEMP\"))\n",
    "\n",
    "# Prepare data for modeling\n",
    "november_data = november_data.select(\"YEAR\", \"MAX_TEMP\")\n",
    "december_data = december_data.select(\"YEAR\", \"MAX_TEMP\")\n",
    "\n",
    "# Assemble features for November and December\n",
    "nov_vector_assembler = VectorAssembler(inputCols=[\"YEAR\"], outputCol=\"features\")\n",
    "november_data = nov_vector_assembler.transform(november_data)\n",
    "\n",
    "dec_vector_assembler = VectorAssembler(inputCols=[\"YEAR\"], outputCol=\"features\")\n",
    "december_data = dec_vector_assembler.transform(december_data)\n",
    "\n",
    "# Train Linear Regression and Random Forest Regression models for November and December\n",
    "lin_model_nov = LinearRegression(featuresCol=\"features\", labelCol=\"MAX_TEMP\").fit(november_data)\n",
    "lin_model_dec = LinearRegression(featuresCol=\"features\", labelCol=\"MAX_TEMP\").fit(december_data)\n",
    "\n",
    "rf_model_nov = RandomForestRegressor(featuresCol=\"features\", labelCol=\"MAX_TEMP\").fit(november_data)\n",
    "rf_model_dec = RandomForestRegressor(featuresCol=\"features\", labelCol=\"MAX_TEMP\").fit(december_data)\n",
    "\n",
    "# Evaluate models\n",
    "lin_nov_metrics = evaluate_model(lin_model_nov, november_data)\n",
    "lin_dec_metrics = evaluate_model(lin_model_dec, december_data)\n",
    "\n",
    "rf_nov_metrics = evaluate_model(rf_model_nov, november_data)\n",
    "rf_dec_metrics = evaluate_model(rf_model_dec, december_data)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Linear Regression November Metrics: RMSE = {:.2f}, MAE = {:.2f}, R2 = {:.2f}\".format(*lin_nov_metrics))\n",
    "print(\"Linear Regression December Metrics: RMSE = {:.2f}, MAE = {:.2f}, R2 = {:.2f}\".format(*lin_dec_metrics))\n",
    "\n",
    "print(\"Random Forest November Metrics: RMSE = {:.2f}, MAE = {:.2f}, R2 = {:.2f}\".format(*rf_nov_metrics))\n",
    "print(\"Random Forest December Metrics: RMSE = {:.2f}, MAE = {:.2f}, R2 = {:.2f}\".format(*rf_dec_metrics))\n",
    "\n",
    "# Compare models and find the highest accuracy model\n",
    "best_model = None\n",
    "best_r2 = -float(\"inf\")\n",
    "best_month = \"\"\n",
    "\n",
    "# Check November models\n",
    "if lin_nov_metrics[2] > best_r2:\n",
    "    best_r2 = lin_nov_metrics[2]\n",
    "    best_model = lin_model_nov\n",
    "    best_month = \"November (Linear Regression)\"\n",
    "    \n",
    "if rf_nov_metrics[2] > best_r2:\n",
    "    best_r2 = rf_nov_metrics[2]\n",
    "    best_model = rf_model_nov\n",
    "    best_month = \"November (Random Forest)\"\n",
    "\n",
    "# Check December models\n",
    "if lin_dec_metrics[2] > best_r2:\n",
    "    best_r2 = lin_dec_metrics[2]\n",
    "    best_model = lin_model_dec\n",
    "    best_month = \"December (Linear Regression)\"\n",
    "    \n",
    "if rf_dec_metrics[2] > best_r2:\n",
    "    best_r2 = rf_dec_metrics[2]\n",
    "    best_model = rf_model_dec\n",
    "    best_month = \"December (Random Forest)\"\n",
    "\n",
    "print(f\"\\nBest model is {best_month} with R2 = {best_r2:.2f}\")\n",
    "\n",
    "# Predict max temperatures for November and December 2024 using the best model\n",
    "year_to_predict = spark.createDataFrame([(2024,)], [\"YEAR\"])\n",
    "year_vector_assembler = VectorAssembler(inputCols=[\"YEAR\"], outputCol=\"features\")\n",
    "prediction_data = year_vector_assembler.transform(year_to_predict)\n",
    "\n",
    "# Use the best model for November\n",
    "nov_pred_2024 = best_model.transform(prediction_data).select(\"prediction\").collect()[0][0]\n",
    "\n",
    "# Predict for December using Linear Regression (since it's the best model for December)\n",
    "dec_pred_2024 = lin_model_dec.transform(prediction_data).select(\"prediction\").collect()[0][0]\n",
    "\n",
    "# Display predictions\n",
    "print(f\"Predicted Maximum Temperature for Cincinnati in November 2024: {nov_pred_2024:.2f}°F\")\n",
    "print(f\"Predicted Maximum Temperature for Cincinnati in December 2024: {dec_pred_2024:.2f}°F\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b6028d-3a78-4db4-b659-3bf51af0a7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
